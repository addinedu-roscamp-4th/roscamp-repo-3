import re
import streamlit as st
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Annotated, Union
from langchain_core.messages import AIMessage, HumanMessage
import speech_recognition as sr
from langgraph.graph.message import add_messages
from gtts import gTTS
import io
import whisper
import sounddevice as sd
import soundfile as sf

# ===== ìƒíƒœ ê´€ë¦¬ í´ë˜ìŠ¤ =====
class OrderState(TypedDict):
    messages: Annotated[List[Union[AIMessage, HumanMessage]], add_messages]
    order: dict

# ===== ìŒì„± ì¸ì‹ ëª¨ë“ˆ =====
def speech_to_text():
    """Whisper ëª¨ë¸ë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    st.info("ë§ì”€í•´ì£¼ì„¸ìš”...", icon="ğŸ¤")
    # 1) ë…¹ìŒ ì„¤ì • (5ì´ˆ, 16kHz, mono)
    sd.default.samplerate = 16000
    sd.default.channels = 1
    recording = sd.rec(int(5 * 16000))  # 5ì´ˆê°„ ë…¹ìŒ
    sd.wait()

    # 2) ì„ì‹œ WAV íŒŒì¼ë¡œ ì €ì¥
    wav_path = "temp_whisper.wav"
    sf.write(wav_path, recording, 16000)

    # 3) Whisper ë¡œë“œ & ì¶”ë¡ 
    model = whisper.load_model("base")      # "tiny", "small" ë“±ìœ¼ë¡œ ê²½ëŸ‰í™” ê°€ëŠ¥
    result = model.transcribe(wav_path, language="ko")
    return result["text"]

# ===== ì£¼ë¬¸ ì²˜ë¦¬ ì—”ì§„ =====
def parse_order(text: str) -> dict:
    """
    ì¬ë£Œ ì£¼ë¬¸ íŒŒì‹±  
    - í–„, ì¹˜ì¦ˆ, ì–‘ìƒì¶”ë§Œ ì¸ì‹  
    - ì¤‘ë³µ ê°€ëŠ¥ 
    - ìµœëŒ€ 3ê°€ì§€ê¹Œì§€
    - ì‚¬ìš©ìê°€ 'ì™„ë£Œ', 'ë', 'ê·¸ë§Œ' ë“±ì˜ í‚¤ì›Œë“œë¥¼ ë§í–ˆëŠ”ì§€ í™•ì¸
    """
    # 1) ì¬ë£Œ í‚¤ì›Œë“œë§Œ ê³¨ë¼ë‚´ê³  ìˆœì„œ ìœ ì§€í•˜ë©´ì„œ ì¤‘ë³µ ì œê±°
    raw = re.findall(r"(í–„|ì¹˜ì¦ˆ|ì–‘ìƒì¶”)", text)
    ingredients = list(dict.fromkeys(raw))[:3]

    # 2) ì‚¬ìš©ìê°€ ì™„ë£Œ ì˜ì‚¬ë¥¼ í‘œí˜„í–ˆëŠ”ì§€ í™•ì¸
    done = bool(re.search(r"(ì™„ë£Œ|ë|ê·¸ë§Œ|ì£¼ë¬¸\s*ì™„ë£Œ)", text))

    return {
        "ingredients": ingredients,
        "done": done,
        "confirmed": False,  # ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° í˜¸í™˜ìš©
    }


def process_order_node(state: OrderState):
    """ì¬ë£Œ ì£¼ë¬¸ ì²˜ë¦¬ ë…¸ë“œ"""
    last_msg = state["messages"][-1].content
    order = parse_order(last_msg)
    ingredients = order["ingredients"]
    done = order["done"]

    # 1) ì•„ì§ ì•„ë¬´ ì¬ë£Œë„ ì„ íƒí•˜ì§€ ì•Šì€ ê²½ìš°
    if not ingredients:
        return {
            "messages": [
                AIMessage("ì¬ë£Œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš” (í–„/ì¹˜ì¦ˆ/ì–‘ìƒì¶”), ìµœëŒ€ 3ê°œê¹Œì§€ ê³ ë¥¼ ìˆ˜ ìˆì–´ìš”.")
            ],
            "order": order,
        }

    # 2) 3ê°œ ë¯¸ë§Œ ì„ íƒ & ì‚¬ìš©ìê°€ ì•„ì§ 'ì™„ë£Œ'ë¥¼ ì•ˆ ë§í•œ ê²½ìš°
    if not done and len(ingredients) < 3:
        sel = ", ".join(ingredients)
        return {
            "messages": [
                AIMessage(
                    f"ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì¬ë£Œ: {sel}.\n"
                    "ì¶”ê°€í•  ì¬ë£Œê°€ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”. "
                    "ì„ íƒì„ ë§ˆì¹˜ì…¨ìœ¼ë©´ 'ì™„ë£Œ'ë¼ê³  ë§í•´ì£¼ì„¸ìš”."
                )
            ],
            "order": order,
        }

    # 3) ì™„ë£Œ í‚¤ì›Œë“œ ì…ë ¥ í˜¹ì€ 3ê°œ ë‹¤ ì±„ìš´ ê²½ìš° â†’ í™•ì¸ ìš”ì²­
    sel = ", ".join(ingredients)
    return {
        "messages": [
            AIMessage(f"{sel} ì¬ë£Œë¡œ ì£¼ë¬¸ì„ í™•ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ë„¤/ì•„ë‹ˆì˜¤)")
        ],
        "order": order,
    }


def confirm_order_node(state: OrderState):
    """ì£¼ë¬¸ í™•ì¸ ë…¸ë“œ"""
    last_msg = state["messages"][-1].content.lower()
    if "ë„¤" in last_msg:
        state["order"]["confirmed"] = True
        return {
            "messages": [AIMessage("âœ… ì£¼ë¬¸ ì™„ë£Œ! ë§¤ì¥ì—ì„œ ë°”ë¡œ ì¤€ë¹„í•©ë‹ˆë‹¤.")],
            "order": state["order"],
        }
    else:
        return {
            "messages": [AIMessage("ğŸ”„ ì£¼ë¬¸ì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.")],
            "order": {},
        }

# ===== ëŒ€í™” íë¦„ ì œì–´ =====
def route_message(state: OrderState):
    last_msg = state["messages"][-1].content.lower()
    if state["order"].get("confirmed"):
        return END
    if any(kw in last_msg for kw in ["ë„¤", "ì•„ë‹ˆì˜¤"]):
        return "confirm"
    return "process"

# ===== Streamlit UI ì„¤ì • =====
st.set_page_config(page_title="ì„œë³´ì›¨ì´ AI ì£¼ë¬¸", page_icon="ğŸ¥ª")
st.title("ğŸ¥ª ì„œë³´ì›¨ì´ AI ì£¼ë¬¸ ì‹œìŠ¤í…œ")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [
        AIMessage("ì–´ì„œì˜¤ì„¸ìš”! ì–´ë–¤ ë©”ë‰´ë¥¼ ì£¼ë¬¸í•˜ì‹œê² ì–´ìš”?")
    ]

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for msg in st.session_state.messages:
    role = "user" if isinstance(msg, HumanMessage) else "assistant"
    st.chat_message(role).write(msg.content)

# ì…ë ¥ ì²˜ë¦¬
input_col, voice_col = st.columns([5, 1])
with input_col:
    text_input = st.chat_input("ì£¼ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
with voice_col:
    if st.button("ğŸ¤", use_container_width=True):
        text_input = speech_to_text()

if text_input:
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    st.session_state.messages.append(HumanMessage(text_input))
    st.chat_message("user").write(text_input)

    # ì£¼ë¬¸ ì²˜ë¦¬ ê·¸ë˜í”„ ì„¤ì •
    workflow = StateGraph(OrderState)
    workflow.add_node("process", process_order_node)
    workflow.add_node("confirm", confirm_order_node)
    workflow.add_conditional_edges(
        "process",
        route_message,
        {"confirm": "confirm", "process": END},
    )
    workflow.add_edge("confirm", END)
    workflow.set_entry_point("process")
    compiled_workflow = workflow.compile()

    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = compiled_workflow.invoke(
        {"messages": st.session_state.messages, "order": {}}
    )

    # AI ì‘ë‹µ í‘œì‹œ
    ai_response = result["messages"][-1]
    st.session_state.messages.append(ai_response)
    st.chat_message("assistant").write(ai_response.content)

    # TTS ë³€í™˜ ë° ì¬ìƒ
    tts = gTTS(ai_response.content, lang="ko")
    buf = io.BytesIO()
    tts.write_to_fp(buf)
    buf.seek(0)
    st.audio(buf.read(), format="audio/mp3")

    # ì¬ì£¼ë¬¸ ì²˜ë¦¬
    if "ë‹¤ì‹œ ì£¼ë¬¸" in ai_response.content:
        st.session_state.messages = [
            AIMessage("ìƒˆ ì£¼ë¬¸ì„ ì‹œì‘í•©ë‹ˆë‹¤. ë©”ë‰´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        ]
        st.rerun()
